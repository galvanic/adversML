
default_parameters:

  experiment: offline training

  dataset_filename: trec2007-1607252257
  label_type:
    ham_label: -1
    spam_label: 1

  classifier:
    type: null
    training_parameters:
      gradient_descent_method: mini-batch
      batch_size: 10
      max_epochs: 100
      initial_weights: null
      convergence_look_back: 2
      divergence_threshold: 1.
    testing_parameters: {}

  attack:
    type: null
    parameters: {}
      percentage_samples_poisoned: .2
      percentage_features_poisoned: .99


parameter_ranges:

  - name: dataset
    key: [dataset_filename]
    values:
#     - trec2007-1607201347 ## 10000 features
      - trec2007-1607252257 ## 1000  features
#     - trec2007-1607252259 ## 100   features
#     - enron-kayla         ## 1000  features

  - name: classifier
    key: [classifier, type]
    values:
      - adaline
      - logistic regression
#     - naive bayes

  - name: attack
    key: [attack, type]
    values:
      - dictionary
      - empty
      - ham
#     - focussed
      - null

  - name: '% poisoned'
    key: [attack, parameters, percentage_samples_poisoned]
    values:
#     - .0
#     - .1
      - .2
#     - .3
#     - .5

# - name: 'attacker knowledge'
#   key: [attack, parameters, percentage_features_poisoned]
#   values:
#     - .20
#     - .50
#     - .90
#     - .95
#     - .98

# - name: learning rate
#   key: [classifier, training_parameters, learning_rate]
#   values:
#     - .5
#     - .2
#     - .1
#     - .05

# - name: GD method
#   key: [classifier, training_parameters, gradient_descent_method]
#   values:
#     - mini-batch
#     - stochastic
#     - batch

# - name: GD batch size
#   key: [classifier, training_parameters, batch_size]
#   values:
#     - 1
#     - 2
#     - 5
#     - 10
#     - 50
#     - 100
#     - 500

# - name: convergence X back
#   key: [classifier, training_parameters, convergence_look_back]
#   values:
#     - 1
#     - 2
#     - 3
#     - 5

